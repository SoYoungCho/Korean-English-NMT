{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import LongTensor\n",
    "from torch.nn import Embedding, LSTM\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 3인 세 문장에 대해 LSTM을 돌려보자.\n",
    "\n",
    "[['안녕', '친구야','반가워','나는','소영'],\n",
    "['친구야','반가워']\n",
    "['나는','소영','친구야','안녕']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Vocabulary를 만든다  \n",
    "Step 2. index 부여된 데이터를 불러온다. (이중 리스트, 내부 리스트는 토큰 인덱스 리스트이다)  \n",
    "Step 3. 모델 만들기\n",
    "Step 4. 가장 긴 시퀀스 길이를 기준으로 내부리스트를 0으로 패딩한다.  \n",
    "Step 5. 내부 리스트를 시퀀스 길이 기준으로 내림차순 정렬한다.  \n",
    "Step 6. 내부 리스트를 임베딩 한다.  \n",
    "Step 7. pack_padded_sequences 를 호출한다. 이 때 임베딩된 instance와 시퀀스 길이를 넘긴다  \n",
    "Step 8. LSTM forward  \n",
    "Step 9. unpack_padded_sequences 를 호출하거나 가장 마지막 히든 벡터를 선택한다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to run LSTM on a batch following 3 token sequences\n",
    "seqs = [['안녕', '친구야','반가워','나는','소영'], #len = 5\n",
    "        ['친구야','반가워'],# len = 2\n",
    "        ['나는','소영','친구야','안녕']]    # len = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Vocabulary 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '나는', '반가워', '소영', '안녕', '친구야']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure <pad> idx is 0\n",
    "vocab = ['<pad>'] + sorted(set([token for seq in seqs for token in seq]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. 인덱싱된 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 5, 2, 1, 3], [5, 2], [1, 3, 5, 4]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Step 2: Load indexed data (list of instances, where each instance is list of character indices) ##\n",
    "##-------------------------------------------------------------------------------------------------##\n",
    "vectorized_seqs = [[vocab.index(token) for token in seq]for seq in seqs]\n",
    "vectorized_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = Embedding(len(vocab), 4) # len(vocab) = 6, embedding_dim = 4\n",
    "lstm = LSTM(input_size=4, hidden_size=5, batch_first=True) # input_dim = 4, hidden_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. 0으로 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 2, 4])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the length of each seq in your batch\n",
    "seq_lengths = LongTensor(list(map(len, vectorized_seqs)))\n",
    "seq_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor = Variable(torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 2, 1, 3],\n",
       "        [5, 2, 0, 0, 0],\n",
       "        [1, 3, 5, 4, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
    "    seq_tensor[idx, :seqlen] = LongTensor(seq)\n",
    "seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_tensor.shape #(batch_size X max_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. 길이로 내림차순 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 5, 2, 1, 3],\n",
       "        [1, 3, 5, 4, 0],\n",
       "        [5, 2, 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
    "seq_tensor = seq_tensor[perm_idx]\n",
    "seq_tensor\n",
    "# seq_tensor => [[ 6  9  8  4  1 11 12 10]           # long_str\n",
    "#                [ 7  3  2  5 13  7  0  0]           # medium\n",
    "#                [12  5  8 14  0  0  0  0]]          # tiny\n",
    "# seq_tensor.shape : (batch_size X max_seq_len) = (3 X 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. 임베딩 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1293, -0.5929, -0.6378, -0.4917],\n",
       "         [-0.1655, -1.1134, -0.2155,  0.0796],\n",
       "         [ 0.0635,  0.0710,  0.1764,  1.3981],\n",
       "         [ 0.0888, -1.3879, -1.3143, -2.0325],\n",
       "         [-0.8205,  0.9168,  2.1129, -0.3407]],\n",
       "\n",
       "        [[ 0.0888, -1.3879, -1.3143, -2.0325],\n",
       "         [-0.8205,  0.9168,  2.1129, -0.3407],\n",
       "         [-0.1655, -1.1134, -0.2155,  0.0796],\n",
       "         [-1.1293, -0.5929, -0.6378, -0.4917],\n",
       "         [-0.7626, -0.9101, -0.1752, -1.0258]],\n",
       "\n",
       "        [[-0.1655, -1.1134, -0.2155,  0.0796],\n",
       "         [ 0.0635,  0.0710,  0.1764,  1.3981],\n",
       "         [-0.7626, -0.9101, -0.1752, -1.0258],\n",
       "         [-0.7626, -0.9101, -0.1752, -1.0258],\n",
       "         [-0.7626, -0.9101, -0.1752, -1.0258]]], grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_seq_tensor = embed(seq_tensor)\n",
    "embedded_seq_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
