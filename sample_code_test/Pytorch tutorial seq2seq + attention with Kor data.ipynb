{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is the most important thing to have creativity when we are young.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self):\n",
    "    # 데이터셋의 전처리를 해주는 부분\n",
    "        data = pd.read_csv('C:/Users/Soyoung Cho/Desktop/NMT Project/dataset/datalist.csv')\n",
    "        #test_data = pd.read_csv('C:/Users/Soyoung Cho/Desktop/NMT Project/dataset/tatoeba_data.csv')\n",
    "    \n",
    "        self.Kor_data = data['Korean']\n",
    "        self.Eng_data = data['English']\n",
    "\n",
    "    def __len__(self):\n",
    "    # 데이터셋의 길이. 즉, 총 샘플의 수\n",
    "        return len(self.Kor_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "    # 데이터셋에서 특정 1개의 샘플을 가져오는 함수.\n",
    "        kor = torch.FloatTensor(self.Kor_data[idx])\n",
    "        eng = torch.FloatTensor(self.Eng_data[idx])\n",
    "\n",
    "\n",
    "dataset = Dataset()\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "print(dataset.Eng_data[0])\n",
    "print(type(dataset.Eng_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # SOS 와 EOS 포함\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유니 코드 문자열을 일반 ASCII로 변환\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소문자, 다듬기, 그리고 문자가 아닌 문자 제거\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    data = Dataset()\n",
    "    #train_loader = DataLoader(test_data, batch_size=2, shuffle=True)\n",
    "    \n",
    "    # 파일을 읽고 줄로 분리\n",
    "    pairs = []\n",
    "    for i in range(1,100000):\n",
    "        sentence_list = []\n",
    "        normalized_kor = normalizeString(data.Kor_data[i])\n",
    "        sentence_list.append(normalized_kor)\n",
    "        normalized_eng = normalizeString(data.Eng_data[i])\n",
    "        sentence_list.append(normalized_eng)\n",
    "        pairs.append(sentence_list)\n",
    "        # [[안녕, 나는, 소영이야], [hi, i, am, soyoung]] 이런 형태로 pairs\n",
    "          \n",
    "    print(pairs)\n",
    "        \n",
    "    #lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "    #    read().strip().split('\\n')\n",
    "\n",
    "    # 모든 줄을 쌍으로 분리하고 정규화\n",
    "    #pairs = [[normalizeString(s) for s in l.split('\\t')] for l in sentence_list]\n",
    "    \n",
    "\n",
    "    # 쌍을 뒤집고, Lang 인스턴스 생성\n",
    "    input_lang = Lang(lang1)\n",
    "    output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 50\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH #and \\\n",
    "        #p[1].startswith(eng_prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한글 문장의 단어 개수 제한, 영어 문장의 단어 개수 제한."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Read 99999 sentence pairs\n",
      "Trimmed to 96560 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "Korean 307553\n",
      "English 88368\n",
      "['프랑스 인상파 화가 클로드 모네(1840∼1926)의 그림 한 점이 미국 뉴욕 소더비 경매에서 1억1170만 달러(약 1318억원)에 팔렸다 .', \"a painting by french impressionist claude monet (1840-1926) was sold for $ 111 .7 million (about krw 131 .8 billion) at the sotheby's auction in new york, usa .\"]\n"
     ]
    }
   ],
   "source": [
    "input_lang, output_lang, pairs = prepareData('Korean', 'English')\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch tutorial (https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.5, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.99\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing 포함: 목표를 다음 입력으로 전달\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Teacher forcing 미포함: 자신의 예측을 다음 입력으로 사용\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=250, plot_every=100, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # print_every 마다 초기화\n",
    "    plot_loss_total = 0  # plot_every 마다 초기화\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # 주기적인 간격에 이 locator가 tick을 설정\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
    "                                                     encoder_hidden)\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30m 31s (- 580m 7s) (250 5%) 10.3217\n",
      "59m 25s (- 534m 47s) (500 10%) 8.5558\n",
      "87m 24s (- 495m 20s) (750 15%) 8.1278\n",
      "118m 26s (- 473m 47s) (1000 20%) 7.9069\n",
      "147m 43s (- 443m 9s) (1250 25%) 7.8172\n",
      "176m 24s (- 411m 36s) (1500 30%) 7.6409\n",
      "204m 16s (- 379m 22s) (1750 35%) 7.5181\n",
      "233m 49s (- 350m 44s) (2000 40%) 7.4564\n",
      "263m 24s (- 321m 56s) (2250 45%) 7.4059\n",
      "290m 52s (- 290m 52s) (2500 50%) 7.3721\n",
      "321m 3s (- 262m 40s) (2750 55%) 7.3313\n",
      "350m 43s (- 233m 49s) (3000 60%) 7.2917\n",
      "380m 18s (- 204m 46s) (3250 65%) 7.2059\n",
      "408m 41s (- 175m 9s) (3500 70%) 7.1450\n",
      "437m 20s (- 145m 46s) (3750 75%) 7.1166\n",
      "466m 13s (- 116m 33s) (4000 80%) 7.2279\n",
      "495m 31s (- 87m 26s) (4250 85%) 7.0461\n",
      "524m 14s (- 58m 14s) (4500 90%) 7.0426\n",
      "554m 10s (- 29m 10s) (4750 95%) 7.1005\n",
      "583m 10s (- 0m 0s) (5000 100%) 6.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD7CAYAAABkO19ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3xVVbbA8d9KIwRCAiSUhF5FpRqpShUHsfBGHbsyjIptVJ46M06f9+ZNUWfsXVRULGNDLDMiUqUKSAfpPUBCC5BAQpL1/jgnGMJN4d57cpN71/fzyYfcc/c9e5+ZuHOyz15riapijDEmfEWFegDGGGO8ZRO9McaEOZvojTEmzNlEb4wxYc4memOMCXM20RtjTJirdKIXkddEJEtEVpU69hMRWS0ixSKSUcnno0VkqYh8HowBG2OMOTNVuaOfAIwoc2wVcCUwuwqfvx9Ye2bDMsYYEywxlTVQ1dki0qbMsbUAIlLhZ0WkBXAp8BfggaoOKiUlRdu0aVNpO2OMMY4lS5bsU9VUX+9VOtEH6Engl0BiZQ1FZCwwFqBVq1YsXrzY46EZY0z4EJFt5b3n2cNYEbkMyFLVJVVpr6ovq2qGqmakpvr8pWSMMcYPXu66GQBcISJbgfeAoSIy0cP+jDHG+ODZRK+qv1bVFqraBrgOmK6qN3nVnzHGGN+qsr3yXWA+0FlEdorIrSLyYxHZCfQDvhCRKW7bNBH5t7dDNsYYcyaqsuvm+nLemuSjbSYw0sfxmcDMMxybMcaYIPAsYEpEWorIDBFZ67a9P5gDN8YYUzVeBkwVAg+qahegL3CPiJztzyCNMcb4r9KJXlVnAwfKHFurqusq+dxuVf3O/f4ITnRsegBjrVBxsfLs9A3MWp/tVRfGGFMrVUtSMzeytiew0Ks+oqKEl2dvZtravV51YYwxtZLnE72I1Ac+Asap6uEK2o0VkcUisjg727+78rTkumQeOubnSI0xJjx5OtGLSCzOJP+2qn5cUdtgRMY6E/1xvz5rjDHhyssUCAK8CqxV1ce96qe0tOR4MnPsjt4YY0rzMmBqAHAzTuqDZe7XaXvsg6l5Ul0O5Z0gN7/Qy26MMaZW8SxgSlXnABXnMQ6y9OS6AOzOOUaHJpUmzDTGmIgQVqUE09yJ3tbpjTHmB56WEhSRESKyTkQ2isjDwRp0edKS4wFs540xxpTiWWSsiEQDzwGXAGcD13sdGdu0QTwiNtEbY0xpnkXGAr2Bjaq6WVULcHLSj/J7pFUQGx1F08R4MnNs6cYYY0p4uUafDuwo9XonFaRACEbAFLhbLO2O3hhjTvJyove140bLaxysUoIWHWuMMafycqLfCbQs9boFkOlhf4A70eccR7Xc3ynGGBNRvJzoFwEdRaStiMThlBP81MP+AEhLiqegsJj9uQVed2WMMbWCZ5GxqloI/ByYgpOi+H1VXe3VhZT4YS+9Ld8YYwx4XEpQVf8NVGsN2dITfbcWydXZtTHG1EhVWropJ2iqkYhMFZEN7r8Ny/nso25w1VoRedpNduaZkol+l0XHGmMMUPU1+gmcHjT1MDBNVTsC09zXpxCR/jjJzboB5wLnA4P8HWxVNEyIJT42it22dGOMMUAVJ3pfQVM4wU9vuN+/AfyXr48C8UAcUAeIBTwtASUi7s4bm+iNMQYC23XTVFV3g1MfFmhStoGqzgdmALvdrymqutbXyYIVMAWQllTXlm6MMcbldYWpDkAXnD306Ti56Qf6ahusgCmw6FhjjCktkIl+r4g0B3D/zfLR5sfAAlU9qqpHgf8AfQPos0rSkuuSfSSf/MIir7syxpgaL5CJ/lNgtPv9aGCyjzbbgUEiEuPWjx2Es6feUyU7b/bm5HvdlTHG1HhV3V55WtAU8HdguIhsAIa7rxGRDBEZ7370Q2ATsBJYDixX1c+CfA2nSUsq2WJpyzfGGFNpwBRUGDQ1zEfbxcBt7vdFwB1+j85PJQVIdtvOG2OM8bvCVFWDpVqJyFdusNQaEWkTvKGXz9IgGGPMD/ytMFVpsJTrTeAxVe2CU4jE1wPboIuPjaZRvTjbYmmMMfhZYYoqBEu5ZQNjVHWqe56jqpoX2HCrzrZYGmOMw99dN5UGSwGdgEMi8rGILBWRx9w6stUiLamurdEbYwzeBkzFABcCD+HkuGkH/LS8xsGMjAVnnX7XwWNWgMQYE/H8neirEiy1E1jqFgcvBD4BepV3wmBGxoKzdJNbUMTh44UBn8sYY2ozfyf6qgRLLQIaikjJrD0UWONnf2fMdt4YY4zDrwpTVCFYyt1D/xAwTURW4hQLf8WbyzhdyURv6/TGmEgXSIWpCoOl3NdTcXLRV7t0K0BijDGAx9krQymlfh1iosSWbowxEc/zUoJu2wYisktEng3GoKsiOkpolhRvlaaMMRHP01KCpfwZmHXGowtQWnJdMm3pxhgT4bwuJYiInAc0Bb7yc4x+S0uKtwyWxpiI52kpQRGJAv4J/KKykwU7YAqcO/o9h49TVGxBU8aYyOX1w9i7gX+r6o7KGgY7YAqcib6oWMk+YgVIjDGRq0r56MuxV0Saq+ruCqJj+wEXisjdQH0gTkSOqmpF6/lB88MWy2M0S4qvji6NMabG8bSUoKreqKqtVLUNTvDUm9U1yQM0dwuQ2BZLY0wk87qUYEhZGgRjjPG4lGCZ4xNwtmlWmwbxsSTWiWF3jm2xNMZELs9KCYpIDxGZLyKrRWSFiFwb7MFXRVpyXdtiaYyJaF6WEswDblHVc9zPPykiyQGM1S/NrdKUMSbCeVZKUFXXq+oG9/tMnF05wdk3eQbSkuva0o0xJqJ5WUrwJBHpDcQBmypoE/SAKXC2WB7ILeBYQVHQzmmMMbWJ59kr3T32bwFjVLW4vHZeBEwBNHf3z2daXnpjTITyspQgItIA+AL4naou8LOvgNgWS2NMpPOslKCIxAGTcIKkPvCzn4CVRMfutiyWxpgI5VkpQeAaYCDwUxFZ5n718OQqKtC0QTwi2BZLY0zE8qyUoKpOBCYGNLogiIuJIrV+HVu6McZELM8rTInIaLfNBhEZ7auN19KS69rDWGNMxPK0wpSINAL+CPQBegN/rKjkoFfSrdKUMSaCeV1h6kfAVFU9oKoHgamc/gvDc2nJTqUpVStAYoyJPJ5WmALSgdJFR3a6x6pVWnJdCgqL2Z9bUN1dG2NMyHkdMCU+jvm8rfYqMhZ+2GJpD2SNMZEokIm+KkFTO4GWpV63ADJ9ncyryFiwoCljTGTztMIUMAW4WEQaug9hL3aPVasfSgraA1ljTOTxtMKUqh4A/gwscr/+1z1WrZITYqkbG2139MaYiOR5hSlVfQ14za/RBYmIkGZ56Y0xEcrz7JU1hVWaMsZEqoAmehG5X0RWueUCx/l4P0lEPhOR5W6bMYH0F4gWDevaHb0xJiL5PdGLyLnA7TgRr92By0SkY5lm9wBrVLU7MBj4p5vVstqlJdVl39ECjp+wAiTGmMgSyB19F2CBquapaiEwC/hxmTYKJIqIAPVxomsLA+jTbyVbLK2soDEm0gQy0a8CBopIYxFJAEZy6p55gGdxfiFkAiuB+8urMuVlwBTYXnpjTOTye6JX1bXAIzj5a74ElnP63fqPgGVAGtADeNatOuXrfJ4FTEHpvfQ20RtjIktAD2NV9VVV7aWqA3GWZTaUaTIG+FgdG4EtwFmB9OmvZklOARK7ozfGRJpAd900cf9tBVwJvFumyXbcvfYi0hToDGwOpE9/xcVE0SSxDrsO2kRvjIksVQqYqsBHItIYOAHco6oHReROAFV9EScqdoKIrMRJcPYrVd0XYJ9+swIkxphIFNBEr6oX+jj2YqnvM3Hy29QIacl1WZN5ONTDMMaYauVpwJTbZrBbGHy1iMwKpL9ApbvRsVaAxBgTSfy+oy8TMFUAfCkiX6jqhlJtkoHngRGqur1kTT9U0pLiTxYgSalfJ5RDMcaYauN1wNQNOLtutgOoqq+c9dXG9tIbYyKR1wFTnYCGIjJTRJaIyC3lnczrgCmwid4YE5n8XrpR1bUiUhIwdRTfAVMxwHk4WyzrAvNFZIGqrvdxvpeBlwEyMjI8WURv0dAKkBhjIo/XAVM7gS9VNdfdVjkbJwFaSCTVjSUhLtr20htjIorXAVOTgQtFJMZd3ukDrA2kz0A4BUgsXbExJrJ4GjDlLu98CawAioHxqroqwD4DYkFTxphI42nAlPv6MeCxQPoJpvTkeNZk5oR6GMYYU208D5hy250vIkUicnUg/QWDFSAxxkQarytMISLROOmMp/jbVzClN7QCJMaYyOJ1wBTAvcBHQEiDpUrYXnpjTKTxNGBKRNJxJv8XfXyeMm09D5iCUgVIbIulMSZCeF1h6kmc1MSVLoh7XWGqRNMGTgESqzRljIkUge66eRV4FUBE/ooTIFVaBvCeUxucFGCkiBSq6ieB9BuIkgIktnRjjIkUAU30ItJEVbNKBUz1K/2+qrYt1XYC8HkoJ/kStpfeGBNJvK4wVSOlJ9dltRUgMcZECM8Dpkod/2kgfQVTenJdvlqzF1XFXVYyxpiw5WnAlIjcKCIr3K95IhKyhGalpSXXPVmAxBhjwp3XAVNbgEGq2g2nUPjL/vYXTLaX3hgTSTwNmFLVeap60H25AGgRQH9Bk5YcD9heemNMZPC6wlRptwL/CaC/oDkZNGV39MaYCOB1hSkARGQIzkR/QXnnE5GxwFiAVq1a+TusKkmqG0u9uGgyrdKUMSYCeF1hChHpBowHRqnq/grOVS2Rse6YrACJMSZieBow5R7/GLjZV53YULKgKWNMpPA6YOoPQGPgeXe/eqGqZgTYZ1CkJddltRUgMcZEAE8DplT1NuC2QPrwSnpy/MkCJPGx0aEejjHGeCagNfrarGQvvRUgMcaEO68jY0VEnhaRjW50bK9A+gumNMtLb4yJEF5Hxl4CdHS/xgIv+NtfsKVbdKwxJkJ4XUpwFPCmOhYAySLSPIA+g6ZZkhUgMcZEBq8jY9OBHaVe73SPnaa6SgmWiI2OomlivN3RG2PCntelBH3lANZyzldtAVMl0pLjbS+9MSbseR0Zu5NT7/JbAJmB9BlMTnSs7boxxoS3QHfdNHH/LYmMfbdMk0+BW9zdN32BHFXdHUifwdS6cQI7DuSx72h+qIdijDGeCXQf/Ucisgb4jFKRsSXRscC/gc3ARuAV4O4A+wuqK3u1oEiVN+dtDfVQjDHGM15HxipwTyB9eKl9an0uPrspb8zfxh2D2lOvTqAZIYwxpuYJdOnmv91gqVUi8q6IxJd5v5WIzBCRpW7A1MjAhht8dwxqT86xE/xr0Y7KGxtjTC0USMBUOnAfkKGq5wLRwHVlmv0OeF9Ve7rvPe9vf17p1aohvds04tU5WzhRVBzq4RhjTNAFukYfA9QVkRgggdN31CjQwP0+ycf7NcIdg9qx69AxvlhRY54TG2NM0ASyj34X8A9gO7AbZ0fNV2Wa/Qm4SUR24jyYvbe881V3wFRpQzo3oWOT+rw4axPOYwVjjAkfgSzdNMRJcdAWSAPqichNZZpdD0xQ1RY4kbNviYjPPkMRMFUiKkoYO7Ad3+85wuwN+6q1b2OM8VogSzcXAVtUNVtVT+BUkupfps2twPsAqjofiAdSAujTM6N6pNO0QR1emrUp1EMxxpigCmSi3w70FZEEccpHDQPW+mgzDEBEuuBM9NW7LlNFcTFR3HpBW+Zt2s+KnYdCPRxjjAmaQNboFwIfAt8BK91zvSwi/ysiV7jNHgRuF5HlOFGzP9UavAh+fe9WJMbH8NLszaEeijHGBE2gAVN/BP5Y5vAfSr2/BhgQSB/VKTE+lpv6tualWZvYtj+X1o3rhXpIxhgTME8Dptw214jIGrfdO4H0Vx3G9G9DTFQUr3xjd/XGmPDgacCUW3Hq18AAVT0HOK3cYE3TpEE8V/ZK54PFO8k+YsnOjDG1n9cBU7cDz6nqQQBVzQqwv2oxdmA7ThQVM36O3dUbY2o/rwOmOgGdRGSuiCwQkRH+D7X6tEutz+Xd03hr/jYO5BaEejjGGBMQrwOmYnAKgw/GCZ4aLyLJ5ZwvZJGxvvx8SAeOnSjiVburN8bUcl4HTO0EJqvqCVXdAqzDmfhPE8rIWF86Nk1k5LnNeWPeNg7l2V29Mab28jpg6hNgCICIpOAs5dSaW+SfD+3A0fxCXpu7NdRDMcYYv3kdMDUF2O9WoZoB/EJV9wc45mrTpXkDfnROU16fu4WcYydCPRxjjPGL1MRA1YyMDF28eHGohwHAql05XPbMHB4Y3on7hvlcdTLGmJATkSWqmuHrvUC3V4a9c9OTuKhLE16ds4Ujx+2u3hhT+3geGeu2u1pEVER8/rap6e4d2pGcYyd4c/62UA/FGGPOmNelBBGRRLfdQn/7CrXuLZMZ3DmV8d9sJje/MNTDMcaYM+J1ZCzAn4FHgeMB9hVS9w7tyMG8E0xcYHf1xpjaxdPIWBHpCbRU1c8rO19NC5gq67zWDbmwYwovz97MsYKiUA/HGGOqzLPIWLdk4BM4OekrVdMCpny5b1hH9ucW8JtJKykqrnm7lYwxxhcvI2MTgXOBmSKyFegLfFpbH8gCnN+mEQ8O78Skpbt48P1lFBYVh3pIxhhTqUAKj5yMjAWO4UTGntz8rqo5lKoPKyIzgYdUtWZskPfTvcM6EhUlPDZlHUUKT1zTnZho26VqjKm5/J7oVXWhiJRExhYCS3EjY4HFqvppkMZY49wzpANRIjzy5fcUq/LktT2ItcneGFNDeVpKsEzbwYH0VdPcNbg90VHw139/T3Gx8vT1PW2yN8bUSJ4GTInIA24ZwRUiMk1EWgc23Jpl7MD2/O7SLvxn1R5+/s53FBTamr0xpubxOmBqqft+N5wEaI/6219NdduF7fjj5WczZfVern9lAZuyj4Z6SMYYcwpPA6ZUdYaq5rkvFwAtAuyvRhozoC1PXdeDjVlHueSpb3huxkZO2I4cY0wN4XUpwdJuBf5T3ps1PWCqMqN6pPP1A4MY3qUpj01ZxxXPzmXVrpxQD8sYYzwvJVjS9iYgA3isvPPVhoCpyqQm1uG5G3vx4k3nse9oPqOem8vf//M9x09YJK0xJnS8LiWIiFwE/Ba4QlXzA+iv1hhxbjO+/u9BXN2rBS/O2sQ1L823tAnGmJDxtJSgm+vmJZxJPiuAvmqdpIRYHrm6Gy/c2IsVO3P47aSV1MQiL8aY8Od1KcHHgPrAByKyTETCNoiqPJd0bc64izry8dJdvGWZL40xIWClBKtBcbFy+5uLmbU+m/fG9iWjTaNQD8kYE2Y8KyVYhYCpOiLyLxHZKCILRaRNIP3VVlFRwuPX9qBFw7rc9fZ3ZB2u1an5jTG1jNcBU7cCB1W1A07K4kf87a+2S6oby0s3Z3D0eCF3vW1RtMaY6uN1halRwBvu9x8Cw9wHtxGpc7NEHr26G0u2HeT/vlgT6uEYYyKE1wFT6cAOt30hkAM09nW+2h4wVVWXd0/j9gvb8ub8bXy4ZGeoh2OMiQBeB0z5unv3+fQ3HAKmqupXI86iX7vG/GbSSuZt2hfq4RhjwpzXAVM7gZYA7vJOEnAggD7DQkx0FM/f2IvWjRK4/Y3FLN9xKNRDMsaEMU8DpoBPgdHu91cD07Um7ucMgYb14ph4Wx8a1Y9j9Ovfsn7vkVAPyRgTprwOmHoVaCwiG4EHgIcDHG9Yadognrdv7UtcdBQ3jV/I9v15PtupKjPWZXHzqwv5ZOmuah6lMaa2s4CpGmD93iNc89J8GsTH8sGd/Wja4IdwhCXbDvDIl+v4dssB6sREkV9YzAPDO3Hv0A5E8AYmY0wZXgZMdXZTG5R8HRaRcWXaJInIZyKy3A2uGhNIn+GoU9NEJozpzf6j+dz86kIO5hawdvdhbp2wiKtemM/m7Fz+d9Q5fPf74fy4ZzqPT13Prz5aUWHO+6JiZfIyJ+1CUXHN+2VujKk+QbujF5FoYBfQR1W3lTr+GyBJVX8lIqnAOqCZqhaUd65Iu6MvMW/TPn76+iIaJsSSdSSf+nViuHNQe8YMaENCnFPeV1V5fOp6npm+kQs7pvD8jb1IjI89eY7iYuXL1Xt4Yup6NmQ51a76t2/ME9f2OOUvBWNMePHsjr6MYcCm0pO8S4FE94FtfZxdN4VB7Dds9G+fwvM39CJKhDsGtuebXw7hniEdTk7yACLCgxd35pGrujJv035+8uJ89uQcR1X5es1eLn1mDne//R3Fqjx7Q08evaobS7cfYsSTs5m2dm8Ir84YEyrBvKN/DfhOVZ8tczwRZ/fNWUAicK2qflHRuSL1jv5MzVqfzd0Tl5AYH0vTpHiW7zhE68YJjLuoI1d0Tyc6ylnD35R9lHvfWcqa3Yf5af82PHzJWcTHRod49MaYYKrojj4oE72IxOGkPzhHVfeWee9qYADOrpv2wFSgu6oeLtNuLDAWoFWrVudt22YpfatiTeZhfjZhEdFRwn3DOnBlrxbERp/+h1p+YRGP/Gcdr83dQpfmDXjm+p50aFI/BCM2xnihOib6UcA9qnqxj/e+AP6uqt+4r6cDD6vqt+Wdz+7oz0x+YRHRIsT4mODLmv79Xh76YAXHCop45OpuXNE9rRpGaIzxWnWs0V8PvFvOe9tx1u8RkaZAZ2BzkPo1QJ2Y6CpN8gBDz2rKl/dfyLnpDbjv3aX85Ys1FFawe8cYU/sFPNGLSAIwHCcFQsmxO0XkTvfln4H+IrISmAb8SlUtwUsINWkQz9u39eWWfq155Zst3PLatxzILXcTlDGmlrOAqQj3weId/PaTVaTWr8NLN5/HuelJZ/R5VUXVKa5ijAmd6tpeaWqhn2S05MM7+6GqXPXCPD6qYupkVeWz5Zlc8MgM7py4xONRGmMCEUia4kqjYt12g933V4vIrMCGa7zQrUUyn917AT1bJfPgB8v58fNzmbxsV7lVsFZn5nDtywu4992lHDtRxFdr9vLtlohPSmpMjRWsXTflRcUmA/OAEaq6XUSaqGpWZeezpZvQKCwq5u2F25kwbytb9uXSJLEON/VtzfW9W5GaWIcDuQX886t1vPvtdpIT4njo4s6M6pHG4H/MpG3jevzrjr6Wf8eYEKlo6SbG10E/lBcVewPwsapuB6jKJG9CJyY6itH923Bz39bM2pDNhLlbeXzqep6dvpGhZzVh3qZ95BYUMbp/G8YN60RSgpN64d6hHfjD5NXM3rCPQZ3Cu2iMMbVRsO7oy4uKfRKIBc7BiYp9SlXfLOccFjBVA23KPsqb87YyaekuurdM5veXnU2npomntCkoLGbIP2bSuH4ck+8ZUG139XtyjlOkSnpy3Wrpz5iazNOAqUqiYp8FMnDu+OsC84FLVXV9Ree0pZva5/3FO/jlhyt46ebz+NE5zTzvr6CwmIufcB75THtw8Ml0D8ZEKq933VyCczfvK2PWTuBLVc11987PBroHoU9Tw1zZM512KfV4/Kv1fqVF3p1zjE+XZ5JXULV8d2/O38rW/Xls3Z/HjO9tRdCYigRjoq8oKnYycKGIxLiBVX04vdygCQMx0VGMG96JdXuP8PmKzErbqyrf7znMM9M2cPkzc+j3t+nc9+5S/jB5daWf3X80n6embeDCjik0T4rntblbgnEJxoStgB7GloqKvaPUsTsBVPVFVV0rIl8CK4BiYLyqrgqkT1NzXda1Oc/P2MgTU9czsmtzn8nVdhzIY8K8rXy1Zg87DhwDoGerZH45ojN7co7z5vxtXHx2Uy6uYPnnya83kFdQxB8uO5upa/fy6Jfr+H7PYc5q1sCzazOmNgtoolfVPKBxmWMvlnn9GPBYIP2Y2iEqysmVf/ubi/loyU6u693q5HsHcgt4dvpG3lqwFUEY0KExdw3qwEVdmtDELYhSUFjM4q0H+fXHK+nVuiEp9euc1sf6vUd459vt3NinFR2bJpJSvw5PT9vAhLlb+ftV3fwe+6bso7RsmEBcjMUQmvDjeSnBUm3PF5EiN22xCVMXdWlC95bJPD1tA/mFRRwrKOK5GRsZ9OgMJszbwtXnteCbXw3h9TG9uaFPq5OTPEBcTBRPXNuDI8cL+e2klfjaKPB/X6wlIS6acRd1AqBhvTh+3DOdSUt3+Z2v5/MVmQz75yyufXk+ew8f9+/CjanBAproVXWdqvZQ1R7AeUAeMKlsOzeg6hFgSiD9mZpPRHjo4k5k5hznoQ9WMOQfM3lsyjr6tGvMlHED+duV3Sosadi5WSIP/agTU1bv5ePvdp3y3ox1Wcxen839wzrSqF7cyeM/7d+W/MJi3v12+xmPd9WuHB76YDmdmyaybs8RLntmDou3WpSvCS/VUUoQ4F7gI8C2R0SACzqk0KdtIz5bnkmzpHjev6Mf40dn0LHM/vvy3HpBO3q3acSfPl3NrkPOOv6JomL+8sVa2qbU45Z+bU5p37lZIhd0SOGt+dsqLJheVtaR49z+5mIaJcQx8bY+fHLPAOrFRXP9KwuYuGCbz78oKlNQWGx/FZgaJ5gT/XX42H0jIunAj4EXT/vEqe3GishiEVmcnZ0dxGGZ6iYiPHN9Tybe2odJd/end9tGZ/T56CjhHz/pTrEqv/hgOcXFyjsLt7Mx6yi/vuQsn+voYwa0Yc/h43y5ak+V+sgvLOLOt5ZwKO8Er4zOIDWxDp2aJjL5ngsY0CGF332yil9/vJL8wqIqna+gsJi3F25jyD9mcuEjM/h+z+HKP2RMNQnKRO8GTV0BfODj7SdxctBX+F+Mqr6sqhmqmpGaamH0tV2TBvFc0DHF7yjZVo0T+P1lZzNv036enr6BJ75eT//2jRl+dlOf7Yd0bkKbxgm8XoWtlqrKbz5exXfbD/H4Nd05J+2H1MxJCbG8Ovp87h3agfcW7eDalxawfMehcif80hP8byetokmDOtSPj+Hhj1b6FU9gjBeCleumoqCpDOA99z/4FGCkiBSq6idB6tuEqWvPb8nUNXt58usNiMDvLj273F8cUVHC6P5t+J/P1rBsxyF6tEwu97yvztnCR9/tZNxFHbmka/PT3o92dw+dk9aAB99fzqjn5hITJXRsmsi5aQ04J60B56YnsW7vEZ6fsYldh47Rs1Uyf72yKwM7pqXe/scAABEbSURBVDB5WSbj/rWMiQu2Mbp/mwqvcfv+PK5/ZQFNGtTh8m5pXNqteYXPMIzxR7By3bwHTFHV1ytpNwH4XFU/rKidpUAwJbKOHOfyZ+ZwybnN+dMV51TY9sjxE/T723SGdWnCU9f19Nlmxrosbp2wiBHnNuPZ63tVWjAl68hxFm05yKrMHFZnHmb1rhz2l9rd07NVMuMu6sTAUn+9qCqjX1/Ekq0HmPrAINLKycVzNL+Qq56fx+6cY6Q3TGDt7sOIQO82jbi8exqXnNuMxj62mBrji9e5bhKAHUA7Vc1xj50MmirTdgI20ZszdPxEEXVioqq0DPQ/n63mrfnbmPvw0JN3xkXFyoqdh5i9fh/jv9lMy0YJfHhXPxLizvwPWlVlz+HjrN51mHp1YujbrpHPce04kMfwJ2ZxQYdUXrnlvNPaFBcrd0xcwvTvs3hjTG8u6JjCxqyjfL4ik8+WZ7IpO5foKOHeoR1ObiU1piKeTvResIne+Gvb/lwG/2Mmt/RtzTlpSczakM3cjfs4lHcCETivVUOeur5ntWS8fHn2Jv767+954cZepy0RPf7VOp6evpE/Xn42Ywa0PeU9Jz3EEZ76egNT1uzho7v606tVQ8/HW1McP+E8D4mPjQ7xSGoXTyZ6EekM/KvUoXbAH1T1yVJtbgR+5b48CtylqssrO7dN9CYQt72xiK/XOjt5mzaow4UdUxnYKZULOqScsv/ea4VFxYx6bi5ZR/L5+oFBJNV18vd/viKTn7+zlGszWvL3q7qW+5fK0fxChj8+iwbxsXx+3wU+U0qUtmHvEV6evZm4mCiS6saSnBBLUl3nKzWxDj1bNqyxtX0Li4qZu2k/nyzdxZTVe2jVKIHJPx9AnRib7KvK8zv6CipM9QfWqupBEbkE+JOq9qnsfDbRm0DsOJDHjHVZ9GnbmE5N64e06tXKnTmMem4O1/VuxV9/3JVVu3K4+sV5nJOWxDu396l0Ivt6zV5ue3Mxv/hRZ+4Z0qHcdvuO5jPq2bkczCsgPjaanGMnTtv1M7JrMx6/pkeNuVNWVZbvzOGTpbv4fEUm+44WkBgfw4D2KXy5eg/3DevIA8Nt2aqqQlZhSlXnlXq5AGgRpP6MKVfLRgmnBVWFStcWSfxsQFvGz9nChR1S+PPna2iYEMeLN51XpbvVi85uysiuzXhq2gZGdm1O25R6p7UpKCzm7onfse9oPh/e2Z+uLZJQVXILijiUV0DOsRPMXJfNY1PWsffwQl65JcOvv2x2Hszj3W+3c6ygmN9f1qXKv0ALi4rZdegYm/flsjk7ly37jrJlXy4bs46y93A+cTFRDDurCaN6pDPkrFTqxETz3/9axgszNzKyazNLVhcEnlaYKtPmIeAsVb2tsvPZHb0JJ3kFhQx/fDa7Dh0jPjaKD+/sz7npSZV/0JV1+DjDHp9F1/Qk3r6tzykTrKrym0mrePfb7Tx1XQ9G9Ugv9zz/Xrmbcf9aRlpSPK+P6e3zl0ZZxcXK7A3ZTFywjenfZ1HyR4Kv5w6+bNufy1UvzGPf0R92KjWIj6Fdan3aptSjb7tGjDi3+cllrRIHcgu46PFZtGyUwMd39bfCMlUQsgpTpdoMAZ4HLlDV/eW0sVKCJmzNXp/N3W9/x9+v6spl3dLO+PNvL9zGbyet4rGru/GTjJYnj781fyu/n7yauwa351cjzqr0PEu2HeD2N5egqowfncF5rX1HLWcdPs4ny3bx9sLtbNufR0r9OK49vyXXZrTitjcXUVBYzNQHBlX63OC2NxYxf9N+/nD52bRPrU+71Po0TIit0l8Dny7P5L53l/K7S7tw24XtKm3vFVXlqWkb+HR5Js/d0IsuzWvmXxheT/SjgHtU9eJy3u+Gk+jskspKCJawO3oTjgqLiompZGIsT3Gxcs1L89mYfZSvHxhESv06zNu0j1te/ZZBnVJ5+ZaMKt/1bt2Xy5gJi9h16BhPXNODoWc1YVVmDsu2H2LZDuerJMdQ7zaNuKlfa0ac0+xk6onp3+/lZxMW8z9XnFNhQNiMdVmMeX0Rv77kLO4Y1P6Mr1lVue2NxczdtI+vxg2iVeOEMz5HoAoKi3n4oxV8vHQX8bFRxMdG89bP+tC1RdX/IqsuXk/05QZLiUgrYDpwS5n1+grZRG/M6TbsPcLIp7/h0q7NefDizlzx7Bwa16/DpLv7kxgfW/kJSjmQW8DYNxezeNtBoqPk5IPbFg3r0r1lMj1bJnNhx1Q6Nzs9EZ2qcsMrC1m39wgzfzGYBj76zi8sYsST3yDAl+MG+p3nf3fOMYY/PpvuLZOYeGufoDxYV1Wen7mJuOgobuzbqtx4ipxjJ7jzrSXM37yfB4Z34r96pHPD+AXk5J1gws96c17rmrXl1bOJvrJgKREZD1wFlKzDFJY3kNJsojfGt8enrufpaRtonhRPbn4hk39+QZXW2n05fqKI52duorhY6dEyme4tk0lNrFok7sqdOVz+7BzuHtyeX/pYMnph5iYe+fJ7Jow5n8Gdm/g1vhITF2zjd5+s4tGrunHN+S0r/0AFVJW/fLGW8XOcnEiN68Vxx6B23NS39SkT/s6DeYx5fRFb9+fyyFXduLKXs48k89AxbnhlAVlH8nl19Pn0a9/YZz+hYAFTxoSJ4yeKGPn0N2zdl8sbP+vNhR1DlwBw3HtL+c+qPcx4aPApaR725Bxn6D9n0r99CuNHV3pfV6niYuW6Vxbw/e7DfP3AoFOK1Zypp752EuSN7teaK3qk8eTXG/hmwz5S6sdxx8D23NS3NZuyjzJmwiKOnyjipZvPo3/7lFPOkXX4ODeMX8iOA3m8cksGAzvVjCSMNtEbE0Z2HTpG5qFjnN/mzNI/B9vOg3kM/ecsLu+Wxj+v6X7y+P3uL4Cv/zt46+qbs48y4qlvGNC+MU9c24PkhDPfHjr+m8383xdrufq8Fjx6VbeTwWOLtx7gya83MGfjPlLq1yGvoJCGCXFMGHN+uTUU9h3N56bxC9mcncvzN/bionKyqlaniiZ6z0sJiuNpEdkoIitEpFcgfRoT6dKT64Z8kgdo0TCBMf3b8PHSnazJdPLvL9p6gMnLMrljYLugPjxtl1qfh0ecxYx12fT723T+9OlqdhzIq/Ln3/t2O//3xVpGdm3G36/sekqEcEabRky8rQ8f3NmPLs0TOTctiUn39K+wUE5K/Tq8N7YvZzVP5M6JS3hh5iYKz6DojS95BYUn/3cMtqDd0VcQHTsSp8LUSKAP8FRl0bF2R29M7ZBz7ASDHptB1/QkJozpzeXPzOFQXgFfPzjIr6RxlVm3x0nz8OnyXRQVKyO7NueOge0r3AXz6fJM7n9vKQM7pvLKLRlBLQB/+PgJfvHBcqas3kv3Fkn84yfdq1xJDZwdUDPWZTFjXTYLNu+nQXws3/5mmF+pKqpl6UZELgb+qKoDyhx/CZipqu+6r9cBg1V1d3nnsonemNqjZEnksm7N+XzFbp69oadfsQJnYnfOMSbM3co7C7dzJL+QjNYN6dQskdT6dUhNdL5S6tdh58E8Hnx/Ob1aN+SNMb2pGxf89A+qyucrdvOHyavIzS9i3PCOjL2wnc+ttEfzC1m89QCz1+9j5rosNu/LBaBdaj2GdG7CkM5N6Ne+sV8BYtU10fuMjhWRz4G/q+oc9/U0nIpTi8u0s4ApY2qh/MIiLnp8FjsOHKNfu8a8c3twtkFWxeHjJ3jv2+18sjSTvYePcyCvgLJTWrcWTkTxmW5BPVPZR/L5w+RV/GfVHrq5d/dNG8SzeOsBFm45wMLN+1mVeZiiYiUuJop+7Roz9KwmDO6cSuvG/u2cKq06kpqVGx0rIl8Afysz0f9SVZeUdz67ozemdpm6Zi+//2QVb/yst8+999XlRFExB3ILyD6ST/bRfI4cL2Rw51Sfe/298sWK3fx+8ioOHztBsSrFCnHRUXRvmUTfdo3p07Yx57VuGPS/LqojqVlFpQR3AqU3v7bA+aVgjAkTw89uykVdmoQ0UyhAbHQUTRvEh7Qc46XdmtO3XSNenLWJhLgY+rRrRK9WDUOaNTRYE/31wLvlvPcp8HM3grYPkFPR+rwxpnYK9SRfkzSuX4ffXnp2qIdxUsATvRsdOxy4o9Sx0qUE/42z42YjkAeMCbRPY4wxVRfwRK+qeUDjMsdeLPW9AvcE2o8xxhj/BBowlSwiH4rI9yKyVkT6lXk/SUQ+E5HlIrJaROxu3hhjqlmgd/RPAV+q6tXuzpuyoXD3AGtU9XIRSQXWicjbqlpw2pmMMcZ4wu+JXkQaAAOBnwK4k3fZCVyBRHGe0tQHDgCF/vZpjDHmzAWydNMOyAZeF5GlIjJeRMru+n8W6IKznXIlcL+q+kwIISJjRWSxiCzOzs4OYFjGGGNKC2SijwF6AS+oak8gF3i4TJsfAcuANKAH8Kz7l8BpVPVlVc1Q1YzU1JqR9tMYY8JBIBP9TmCnqi50X3+IM/GXNgb4WB0bgS1A5YUtjTHGBI3fa/SqukdEdohIZ1VdBwwD1pRptt09/o2INAU6A5srO/eSJUv2iYi/yW5SgH1+frY2s+uOLHbdkaUq1926vDcCLSXYAxgPxOFM4GOAa+FkKcE0YALQHBCc5GYT/e6wamNaXJVyheHGrjuy2HVHlkCvO6Dtlaq6DCjbeelgqUzg4kD6MMYYE5jgZeA3xhhTI4XjRP9yqAcQInbdkcWuO7IEdN01sji4McaY4AnHO3pjjDGl2ERvjDFhLmwmehEZISLrRGSjiJSN0A0rIvKaiGSJyKpSxxqJyFQR2eD+2zCUYww2EWkpIjPcLKmrReR+93hYXzeAiMSLyLelssD+j3u8rYgsdK/9X25iwbAiItFuipXP3ddhf80AIrJVRFaKyDIRWewe8/tnPSwmehGJBp7DKWl4NnC9iNSc8i7BNwEYUebYw8A0Ve0ITOP0dBS1XSHwoKp2AfoC97j/H4f7dQPkA0NVtTtOKpERItIXeAR4wr32g8CtIRyjV+4H1pZ6HQnXXGKIqvYotX/e75/1sJjogd7ARlXd7GbRfA8YFeIxeUZVZ+NkAi1tFPCG+/0bwH9V66A8pqq7VfU79/sjOP/xpxPm1w1O8R5VPeq+jHW/FBiKk3oEwvDaRaQFcClOUCZuFtywvuZK+P2zHi4TfTqwo9Trne6xSNK0pBav+2+TEI/HMyLSBugJLCRCrttdwlgGZAFTgU3AIVUtSfsdjj/zTwK/BEoy3jYm/K+5hAJficgSERnrHvP7Zz1YxcFDzVdVYts3GoZEpD7wETBOVQ9HSkFqVS0CeohIMjAJJ/33ac2qd1TeEZHLgCxVXSIig0sO+2gaNtdcxgBVzRSRJsBUEfk+kJOFyx39TqBlqdctcHLgR5K9ItIcwP03K8TjCToRicWZ5N9W1Y/dw2F/3aWp6iFgJs5zimQRKblZC7ef+QHAFSKyFWcpdijOHX44X/NJbvoYVDUL5xd7bwL4WQ+XiX4R0NF9Ih8HXAd8GuIxVbdPgdHu96OBySEcS9C567OvAmtV9fFSb4X1dQOISKp7J4+I1AUuwnlGMQO42m0WVteuqr9W1Raq2gbnv+fpqnojYXzNJUSknogklnyPky9sFQH8rIdNZKyIjMT5jR8NvKaqfwnxkDwjIu8Cg3FSl+4F/gh8ArwPtMJJD/0TVS37wLbWEpELgG9wKpWVrNn+BmedPmyvG0BEuuE8fIvGuTl7X1X/V0Ta4dztNgKWAjepan7oRuoNd+nmIVW9LBKu2b3GSe7LGOAdVf2LiDTGz5/1sJnojTHG+BYuSzfGGGPKYRO9McaEOZvojTEmzNlEb4wxYc4memOMCXM20RtjTJizid4YY8Lc/wMuMy6P+mMHxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 5000, print_every=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 그가 1989년 미국에서 출간한 ‘디스커버링(discovering)’은 위대한 과학자들의 창의성·관찰력·통찰력 등이 빛나는 순간과 발견 과정을 다룬 책으로 1990년 la타임스가 ‘올해의 책’으로 선정했다 .\n",
      "= \"discovering,\" which he published in 1989 in the u .s ., is a book about the moments of great scientists' creativity, keen observation and insight and their discovery process, and it was selected by the los angeles times as the \"book of the year\" in 1990 .\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head\n",
      "\n",
      "> 국내에서도 큰 주목을 받았던 이창동 감독의 ‘버닝’은 연말 분위기가 물씬 다가온 뉴욕에서 여전히 조용하지만 뜨겁게 뉴욕 시민들에게 다가가고 있다 .\n",
      "= director lee chang-dong's \"burning,\" which also received much attention in korea, is still reaching new yorkers quietly but hotly in new york, where the year-end atmosphere is coming .\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the national of the head of the head of the head\n",
      "\n",
      "> 수시의 비율이 월등히 높은 것으로 보이지만 서울과 경인지역 대학만을 보면 수시와 정시 비율이 크게 차이나지 않는다는 점에 주목해야 한다 .\n",
      "= it should be noted that the ratio of students applying for non-scheduled admission process seems much higher, but the ration for universities in seoul and gyeong-in is not significantly higher compared to that of students applying for regular admission .\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the national of the head of the head of the head of the head\n",
      "\n",
      "> 직접 야외로 나와서 도시의 역사를 걷고 느끼고 하는 새로운 접근방식을 배운 것 같습니다 .\n",
      "= i learned a new approach of taking a walk outside and feeling the history of the city .\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the national of the head of the head\n",
      "\n",
      "> 아이들이 비행으로 피곤해 하는데 즐겁게 해 줄 수 있는 곳이 있을까요 ?\n",
      "= is there a place that could amuse my children who are tired from the long flight hours ?\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head\n",
      "\n",
      "> 너 계속 고민하더니 결국엔 회사 그만두기로 한 거야 ?\n",
      "= you kept thinking and you finally decided to quit the job ?\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head\n",
      "\n",
      "> 실무위원회 심의의 공정을 기하기 위해 안건과 직접 이해관계가 있는 위원은 회의에 참석할 수 없으며, 위원 본인 또는 관계인의 요청에 의해 심의에서 제외될 수 있다 .\n",
      "= any member who has a direct interest in an agenda item to ensure fairness in deliberation on the working committee shall be prohibited from attending the meeting and may be excluded from deliberation at the request of the member himself/herself or a related person .\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head\n",
      "\n",
      "> 소비자 인식조사, 전문가 브랜드 가치 평가, 서류 심사 등을 거쳐 각 산업 부문별로 최고 평가를 받은 브랜드만이 수상의 영예를 누리게 된다 .\n",
      "= only brands that received the highest ratings in each industry sector will enjoy the honor of the award after conducting consumer awareness surveys, expert brand value assessments and document screening .\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the national of the head of the head of the head\n",
      "\n",
      "> 석유·화학·철강업의 대정비·보수작업, 조선업의 시운전, 건설업의 기상악화로 인한 공기 지연 등의 경우 이를 이용해 근로시간 총량을 한시적으로 늘릴 수 있게 해 달라는 게 업계의 요구다 .\n",
      "= in case of major maintenance and repair work in the oil, chemical and steel industries, test-runs in the shipbuilding industry, and delays in the air caused by bad weather in the construction industry, the industry is asking for a temporary increase in the total amount of working hours .\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head\n",
      "\n",
      "> 이인영 더불어민주당 원내대표가 10일 원내수석부대표에 재선의 이원욱 의원을 선임했다 .\n",
      "= lee in-yeong, the floor leader of the democratic party of korea, appointed lee won-uk, a second-term congressman, as his vice floor leader on the 10th .\n",
      "< the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the head of the national of the head of the head\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
