{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchtext import data, datasets\n",
    "\n",
    "PAD = 1\n",
    "BOS = 2\n",
    "EOS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "\n",
    "    def __init__(self, train_fn = None, \n",
    "                    valid_fn = None, \n",
    "                    exts = None,\n",
    "                    batch_size = 64, \n",
    "                    device = 'cpu', \n",
    "                    max_vocab = 99999999,    \n",
    "                    max_length = 255, \n",
    "                    fix_length = None, \n",
    "                    use_bos = True, \n",
    "                    use_eos = True, \n",
    "                    shuffle = True\n",
    "                    ):\n",
    "\n",
    "        super(DataLoader, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        * sequential : 데이터의 유형이 연속형 데이터인지(False면 토큰화가 적용x)\n",
    "        * use_vocab : Vocab 사용 여부(False면 필드의 데이터는 이미 숫자여야함)\n",
    "        * batch_first : 배치 수가 먼저 텐서를 생성할지 여부\n",
    "        * include_lengths : 패딩 된 미니 배치의 튜플과 각 예제의 길이를 포함하는 목록 \n",
    "                            또는 패딩 된 미니 배치를 반환할지 여부(default: False)\n",
    "        * fix_length : 모든 문장이 채워지는 고정 길이, 유연한 sequence의 경우 None\n",
    "        * init_token : 모든 문장 앞에 추가되는 토큰\n",
    "        * eos_token : 모든 문장 뒤에 추가되는 토큰\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        self.src = data.Field(sequential = True,\n",
    "                                use_vocab = True, \n",
    "                                batch_first = True, \n",
    "                                include_lengths = True, \n",
    "                                fix_length = fix_length, \n",
    "                                init_token = None, \n",
    "                                eos_token = None\n",
    "                                )\n",
    "        super(DataLoader, self).__init__()\n",
    "\n",
    "        self.tgt = data.Field(sequential = True, \n",
    "                                use_vocab = True, \n",
    "                                batch_first = True, \n",
    "                                include_lengths = True, \n",
    "                                fix_length = fix_length, \n",
    "                                init_token = '<BOS>' if use_bos else None, \n",
    "                                eos_token = '<EOS>' if use_eos else None\n",
    "                                )\n",
    "        \n",
    "        \n",
    "        \n",
    "#         if train_fn is not None and valid_fn is not None and exts is not None:\n",
    "            \n",
    "        train = TranslationDataset(path = train_fn, exts = exts,\n",
    "                                        fields = [('src', self.src), ('tgt', self.tgt)], \n",
    "                                        max_length = max_length\n",
    "                                        )\n",
    "        valid = TranslationDataset(path = valid_fn, exts = exts,\n",
    "                                        fields = [('src', self.src), ('tgt', self.tgt)], \n",
    "                                        max_length = max_length\n",
    "                                        )\n",
    "\n",
    "        self.train_iter = data.BucketIterator(train, \n",
    "                                                batch_size = batch_size, \n",
    "                                                shuffle = shuffle, \n",
    "                                                sort_key=lambda x: len(x.tgt) + (max_length * len(x.src)), \n",
    "                                                sort_within_batch = True\n",
    "                                                )\n",
    "\n",
    "        self.valid_iter = data.BucketIterator(valid, \n",
    "                                                batch_size = batch_size, \n",
    "                                                shuffle = False, \n",
    "                                                sort_key=lambda x: len(x.tgt) + (max_length * len(x.src)), \n",
    "                                                sort_within_batch = True\n",
    "                                                )\n",
    "\n",
    "        self.src.build_vocab(train, max_size = max_vocab)\n",
    "        self.tgt.build_vocab(train, max_size = max_vocab)\n",
    "\n",
    "    def load_vocab(self, src_vocab, tgt_vocab):\n",
    "        self.src.vocab = src_vocab\n",
    "        self.tgt.vocab = tgt_vocab\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defines a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110293\n",
      "1111033\n",
      "(tensor([[  12942,  197180,    1658,     792,  734851,     573,     614,   17296],\n",
      "        [   3581,    3582,  223993,  211283,     469,      28,     756,    2873],\n",
      "        [     60,     239,    9267,   19978,      15,      30,    1791,   18329],\n",
      "        [  53413,  138005,    5114,  158971,      31,       8,  477815,       1],\n",
      "        [  59446,  286629,  363804, 1084290,   18051,       8,  228006,       1],\n",
      "        [   2164,     684,   18431,  913551,     102,      25,  108882,       1],\n",
      "        [    141,  730159,   16248,      15,       7,  496405,       1,       1],\n",
      "        [ 481901,       1,       1,       1,       1,       1,       1,       1]]), tensor([8, 8, 8, 7, 7, 7, 6, 1]))\n",
      "(tensor([[      2,    1550,     774,   62223,   81476,    6186,    1266,  202147,\n",
      "           21772,      25,      40,    5455,    1008,     615,      18,       4,\n",
      "           54104,       3,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1],\n",
      "        [      2,  419685,     248,  904500,   76788,  677606,    1304,      24,\n",
      "            3726,       7,    2290,     351,     562,       4,    1290,    2946,\n",
      "               3,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1],\n",
      "        [      2,     533,  210299,  979489,    1380,   53021,    5672,  717892,\n",
      "              58,     630,       8,  148857,       6,   16359,       3,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1],\n",
      "        [      2,  231427,   66715,    1604,   12075,    1608,    7288,    1639,\n",
      "           56477,    2326,     981,   30624,   25920,      95,    1322,    1203,\n",
      "           32602,   14192,   66715,    1604,    5479,   11246,      22,     418,\n",
      "             332,     374,       5,     439,     187,    1259,      39,      15,\n",
      "              24,    1107,     303,       7,    1506,  426854,     918,     829,\n",
      "              78,       4,      63,       5,       4,     123,      10,    1442,\n",
      "             210,     532,       7,       4,     419,     672,    6332,       4,\n",
      "             374,       5,     332,       5,     439,     187,    1259,      79,\n",
      "              15,   48908,       3],\n",
      "        [      2,  654087,  997277,  665964,  873429,      35,   12475,   46294,\n",
      "          642847,    9248,    5378,     120,   67402, 1038673,      99,  280303,\n",
      "          777070,    4446,      22,    1912,      28,      37,     934,       4,\n",
      "             428,    1248,      18,     360,       4,     663,      27,    5642,\n",
      "             262,      13,       4,    2990,   19811,       5,     384,   13344,\n",
      "            1248,       5,       4,     695,    6360,   56589,      28,      37,\n",
      "            4230,       4,     695,    6360,   16991,   34199,      80,       4,\n",
      "           38587,  183133,    1227,    7105,       3,       1,       1,       1,\n",
      "               1,       1,       1],\n",
      "        [      2,   10930,   18086,    2966,    6735,    3159,   34883,   89046,\n",
      "            1717,   13712,  860649,    2325,   13084,   18477,  299313,    7942,\n",
      "             960, 1095152,  220824,    1913,   82523,    1121,     347,       6,\n",
      "            2198,     347,      65,   15498,      68,      13,       4,  143817,\n",
      "            5873,  356582,      46,       6,    2760,     108,     655,      53,\n",
      "             654,       9,    2337,      16,       8,    1509,      13,   22329,\n",
      "            9371,     982,     117,      91,    1988,       6,      91,    8499,\n",
      "          550559,      47,       3,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1],\n",
      "        [      2,    2497,  164781,   23498,   11983,   82943,      21,     596,\n",
      "              28,    2153,    7778,      14,      28,   30404,       3,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1],\n",
      "        [      2,  483220,       3,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1]]), tensor([18, 17, 15, 67, 61, 59, 15,  3]))\n",
      "(tensor([[     40,    6137,  344447,   92157,       8,       2,   34931,     812,\n",
      "            5925],\n",
      "        [  18799,    3742,  999257,    9972,  777914,      31,       8,  478989,\n",
      "           17066],\n",
      "        [    255,  105783, 1068828,  785937,      25,     149,      27,     519,\n",
      "          183386],\n",
      "        [   2220,    8790,     613,   25875,  200278,     769,      90,      94,\n",
      "            5012],\n",
      "        [   1630,   23822,   58388,    7553,      20,   12711,      36,     519,\n",
      "           28798],\n",
      "        [    142,  598361,  212177,      17,      13,       7,      95,  127207,\n",
      "               1],\n",
      "        [     40,   13849,    3595,  990307,   14961,       8,      71,  109929,\n",
      "               1],\n",
      "        [     40,  114967,  328591,  762347,      17,       7,      31,  108684,\n",
      "               1]]), tensor([9, 9, 9, 9, 9, 8, 8, 8]))\n",
      "(tensor([[     2, 173661,  13064, 127691,  19071,  44545, 220344,  45768,     42,\n",
      "          28509,     66,     67,  18360,   1938,  55901,    966, 755793,     66,\n",
      "          17588,  83513,    492,   9266,      4,    106,    671,      6,      4,\n",
      "            824,    692,     25,     68,     11,     51,     21,   1535,   2928,\n",
      "           3481,      7,      4,    106,  56543,    388,      9,    389,   1478,\n",
      "           1592,     61,      4,    192,     26,     40,   9290,     26,     30,\n",
      "         183142,      3,      1],\n",
      "        [     2,   6143,  99407,  52040, 278338, 163723,  14192,   7089,   1026,\n",
      "         220718,     22,    344,   2385,      5,      4,    434,      5,    522,\n",
      "             79,   3690,      6,   5686,      4,    439,    187,      5, 521908,\n",
      "            349,   2908,      6,  25159,     18,      4,     63,      5,      4,\n",
      "            698,      5,    522,   1372,  24526,      3,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     2, 776489,    107,   2436,    622,  31679,     99,  15810,   9788,\n",
      "         313086, 138058,   5576,   3919,   3564,  72210,   1643, 906039,  79210,\n",
      "           1650,      8,   7585,   1765,     78,     19,   2921,     97,   2058,\n",
      "           4100,      8,  20811,     13,    165,   9506,     13,      4,  27285,\n",
      "              3,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     2,    333,     67,   4724,  29830,   1879, 896633,     20,  28794,\n",
      "              7,    156,  37359,      9,   1265,      5,   9680,      3,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     2, 162033,    942,   8825,   7135,     22,  66944,     28,  10089,\n",
      "            158,      9,   1877, 254393,      3,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     2,  93298,   1718, 225460, 580913,   7783,  36745,  13233,   1663,\n",
      "         809461, 303222,  77564, 111174,  12104,  85333,   1645, 761887,      4,\n",
      "         356702,      5,   3283,   2216, 500206,     31,     17,   2282,     18,\n",
      "              8,  15549,  15145,   9594,     19,     17,   2231,     61,      4,\n",
      "            758,   3161,   1216,     34,    883,     70,    947,     50,   8070,\n",
      "           3503,   3262,     18,  15549,  15145,     71,   2054,     76,     81,\n",
      "             50,  17731,      3],\n",
      "        [     2, 382343, 778222, 104453, 331478,   4145, 830049,   7362,  26608,\n",
      "          21619,    172, 810447,    470, 759967, 128089, 830055,      4,    769,\n",
      "             10,  20057,      4,   1434,     21,   3000,     16,  68844,  22800,\n",
      "              6,     15,  17753,     18,    739,   3092,    232,   3765,     36,\n",
      "          16366,    359,   3055,      3,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1],\n",
      "        [     2,  14043,    140,    215,  12670,  18971,    391,   7215,  16719,\n",
      "           2625,      5,   1248,     20,     43,     11,   3966,    854,      4,\n",
      "          74169,      3,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "              1,      1,      1]]), tensor([56, 42, 37, 17, 14, 57, 40, 20]))\n",
      "(tensor([[  9689,  94373,   6971,  77819,     90,     25,      5, 538464,      2,\n",
      "          46734],\n",
      "        [941535,   1011, 743526,   1326,      8,     17,      5,      2,  15120,\n",
      "         146559],\n",
      "        [  3918,  33517, 114232,  34196, 951215,     22,   1114,      8,     28,\n",
      "          73622],\n",
      "        [  4739,  57485, 403990,   2793,   1421,    547,   5180,     22,    741,\n",
      "          18850],\n",
      "        [   141,   6172,  17692, 214871,  70247,   2952,      5,      2,   8140,\n",
      "          29670],\n",
      "        [   107,   2688,  12006,   9777,     20,   9411,    573,   3373,     17,\n",
      "           9087],\n",
      "        [   141,  45759,   1170,     87,    806,  34462,     36,  19540,      6,\n",
      "          26888],\n",
      "        [ 33214,  19030, 862014,    244,   6862,    159,   1745,      8,      6,\n",
      "          87957]]), tensor([10, 10, 10, 10, 10, 10, 10, 10]))\n",
      "(tensor([[      2,   15612,   16098,  688948,  652345,    9444,     135,  911760,\n",
      "           10414,  221872,   38214,  413136,  321448,  643764,  935379,      17,\n",
      "            4323,     759,     801,       4,     275,   12419,       9,  491522,\n",
      "           26101,       6,       9,  121334,     926,   20798,   17761,       7,\n",
      "               4,  151764,  471080,      14,     114,   33090,      71,     399,\n",
      "               7,     401,     662,       3],\n",
      "        [      2,    8845,   21012,   30787,    3212,    6849,  153091,  162918,\n",
      "            5912,   40588,      22,     201,  578943,  733966,  335736,   11681,\n",
      "             679,   11695,      21,     507,       8,  360799,    3783,    1160,\n",
      "           60187,   53846,      54,      11,     309,      37,     904,    3387,\n",
      "               6,     674,      53,     568,       9,      53,    1074,   10273,\n",
      "               3,       1,       1,       1],\n",
      "        [      2,    5680,    2152,  103162,  311141,  584849,  882879, 1059049,\n",
      "           53839,  244043,    5258,     415,   61648,    1351,  948282,    1637,\n",
      "          472136,   94993,    5082,  495053,      81,       5,       4,     203,\n",
      "            5526,   20400,       9,     328,      10,      61,       7,    5175,\n",
      "              13,       4,   53839,    7714,    8746,       3,       1,       1,\n",
      "               1,       1,       1,       1],\n",
      "        [      2,   75333,   19237,   50475,  190992,    5140,   30851,  657671,\n",
      "              18,  458889,  580006, 1098213,  507158,     130,      99,    2197,\n",
      "            9709,   42196,    1278,   21354,  322031,  181179,      26,    5808,\n",
      "              13,    4760,    1941,    1268,      80,      59,    2164,  120539,\n",
      "              18,  122381,       6,  356988,  182521,       3,       1,       1,\n",
      "               1,       1,       1,       1],\n",
      "        [      2,     544,  622278,  321249,     455,   39717,     544,    3147,\n",
      "         1084179,      40,       8,     311,     138,     127,      72,    1171,\n",
      "            1928,    3777,     102,      28,     164,       7,     160,     672,\n",
      "              50,   41899,       3,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1],\n",
      "        [      2,    1777,    4864,   50618,   55774,    7318,   85698,    5261,\n",
      "            9124,    7663,       4,    1602,       5,     611,    7759,    2033,\n",
      "              43,      10,      32,     753,  110354,       3,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1],\n",
      "        [      2,  721129,  349549,   46356, 1055567,   81667,    4273,  224441,\n",
      "            4921,       4,   23712,    6997,       4,     690,       4,   13192,\n",
      "               6,       4,   80636,      47,       3,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1],\n",
      "        [      2,  343444,     711,   21734,   49863,   11970,   40664,   21668,\n",
      "              29,     990,     353,      49,      72,      25,       7,      15,\n",
      "              23,       4,    2487,  148711,       3,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1,       1,       1,       1,       1,\n",
      "               1,       1,       1,       1]]), tensor([44, 41, 38, 38, 27, 22, 21, 21]))\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "class TranslationDataset(data.Dataset):\n",
    "\n",
    "    def sort_key(ex):  # 음수와 양수 모두 가능\n",
    "        return data.interleave_keys(len(ex.src), len(ex.trg))\n",
    "\n",
    "    def __init__(self, path, exts, fields, max_length=None, **kwargs):\n",
    "        \n",
    "        \"\"\"\n",
    "        * path : 두 언어의 데이터 파일 경로\n",
    "        * exts : 각 언어의 경로 확장을 포함하는 튜플\n",
    "        * fields : 각 언어의 데이터에 사용될 필드를 포함하는 튜플\n",
    "        * **kwargs : 생성자에 전달 \n",
    "        \"\"\"\n",
    "        if not isinstance(fields[0], (tuple, list)):\n",
    "            fields = [('src', fields[0]), ('trg', fields[1])]\n",
    "\n",
    "#         if not path.endswith('.'):\n",
    "#             path += '.'\n",
    "\n",
    "        src_path, trg_path = tuple(os.path.expanduser(path + x) for x in exts)\n",
    "        \n",
    "        examples = []\n",
    "        with open(src_path) as src_file, open(trg_path) as trg_file:\n",
    "            for src_line, trg_line in zip(src_file, trg_file):\n",
    "                src_line, trg_line = src_line.strip(), trg_line.strip()\n",
    "                if max_length and max_length < max(len(src_line.split()), len(trg_line.split())):\n",
    "                    continue\n",
    "                if src_line != '' and trg_line != '':\n",
    "                    examples.append(data.Example.fromlist(\n",
    "                        [src_line, trg_line], fields))\n",
    "\n",
    "        super(TranslationDataset, self).__init__(examples, fields, **kwargs)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\"\n",
    "    argv1,2 : train.csv와 test.csv파일이 있는 공통 경로\n",
    "    (argv3, argv4) : 확장자를 포함한 각 파일 이름\n",
    "    \n",
    "    \"\"\"\n",
    "    loader = DataLoader('C:/Users/USER/Capstone/','C:/Users/USER/Capstone/' , ('train.csv','test.csv'),\n",
    "                        shuffle = False, \n",
    "                        batch_size = 8\n",
    "                        )\n",
    "    \n",
    "    \n",
    "    print(len(loader.src.vocab))\n",
    "    print(len(loader.tgt.vocab))\n",
    "\n",
    "    for batch_index, batch in enumerate(loader.train_iter):\n",
    "        print(batch.src)\n",
    "        print(batch.tgt)\n",
    "\n",
    "        if batch_index > 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-42ccde2e3ee3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdata_loader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimple_nmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq2seq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSeq2Seq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'data_loader'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from data_loader import DataLoader\n",
    "import data_loader\n",
    "from simple_nmt.seq2seq import Seq2Seq\n",
    "import simple_nmt.trainer as trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://books.google.co.kr/books?id=LV2nDwAAQBAJ&pg=PA145&lpg=PA145&dq=__init__(self,+train_fn+%3D+None&source=bl&ots=uhXWUwlTcz&sig=ACfU3U0AcrutNKVXJ19pieVc0xctnQOzTA&hl=ko&sa=X&ved=2ahUKEwj6u4-fuM7nAhXYP3AKHfKuDNoQ6AEwAHoECAsQAQ#v=onepage&q=__init__(self%2C%20train_fn%20%3D%20None&f=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
